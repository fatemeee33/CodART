[REFACTORING]
types = extract_class,move_method,pull_up_method,push_down_method,extract_method

[RELATIONS]
GOD_CLASS_PATH = "/home/y/PycharmProjects/smell_csvs/JSON20201115/God-Class_JASON-20201115.csv"
FEATURE_ENVY_PATH = "/home/y/PycharmProjects/smell_csvs/JSON20201115/Feature-Envy2_JASON-20201115.csv"
LONG_METHOD_PATH = "/home/y/PycharmProjects/smell_csvs/JSON20201115/Long-Method2_JASON-20201115.csv"



[UNDERSTAND]
sys_path_object = /home/y/Downloads/understand/Understand-6.5.1183-Linux-64bit/scitools/bin/linux64/Python
sys_path_index = 0
os_environs_key = LD_LIBRARY_PATH
os_environs_value = /home/y/Downloads/understand/Understand-6.5.1183-Linux-64bit/scitools/bin/linux64/Python

[CORE]
option = 1

[Config]
repo_address = /home/y/Desktop/desktop_0./CodART/benchmark_projects/JSON-java
db_address = /home/y/Desktop/desktop_0./CodART
db_name = mydb.udb
engine_core = Python3
PROJECT_LOG_DIR = /home/y/pythonProjects/CodeArt/
POPULATION_SIZE = 100
LOWER_BAND = 10
UPPER_BAND = 50
OBJECTIVE = 8
evaluate_in_parallel = True
verbose_design_metrics = True
PROJECT_NAME = JSON


[METRICS]
initial_value_modularity = 1.0
initial_value_testability = 1.0


[Logging]
filename = /home/y/Desktop/desktop_0./CodART/a.log
level = DEBUG

[MODEL_PATHS]
scaler1_path = models/DS07510.joblib
model5_path = models/DS07710.joblib
model_branch_path = models/VR1_DS5.joblib
model_line_path = models/VR1_DS7.joblib

[COD2VEC]
SHOW_TOP_CONTEXTS = 10
MAX_PATH_LENGTH = 8
MAX_PATH_WIDTH = 2
JAR_PATH = /home/y/PycharmProjects/CodART/codart/learner/cod2vec/JavaExtractor/JPredict/target/JavaExtractor-0.0.1-SNAPSHOT.jar
EXPORT_CODE_VECTORS = False
MAX_CONTEXTS = 1000

[TRAINING]
torch_manual_seed = 0
frames_per_batch = 6000  # Number of frames collected per training iteration
n_iters = 10  # Number of sampling and training iterations
num_epochs = 30  # Number of optimization steps per training iteration
minibatch_size = 400  # Size of the mini-batches in each optimization step
learning_rate = 0.0003  # Learning rate
max_grad_norm = 1.0  # Maximum norm for the gradients
max_steps = 100

[PPO]
clip_epsilon = 0.2  # Clip value for PPO loss
gamma = 0.99  # Discount factor
lambda = 0.9  # Lambda for generalized advantage estimation
entropy_eps = 0.0001  # Coefficient of the entropy term in the PPO loss
scenario_name = navigation
n_agent = 2
continuous_actions = True
centralised = False
depth = 2
num_cells = 256
share_parameters_critic = True